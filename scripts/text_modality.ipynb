{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309e30cd",
   "metadata": {},
   "source": [
    "Preprocesamiento basado en paper:\n",
    "\n",
    "\"we preprocess them by removing stop words, non-ASCII charachters, numbers, URLs and hashtag signs. we also replace all punctuation marks with white spaces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34681525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (2.3.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from torch) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.9.0-cp313-cp313-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/109.3 MB 5.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 2.4/109.3 MB 5.9 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 3.4/109.3 MB 6.0 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 4.5/109.3 MB 5.7 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.8/109.3 MB 5.5 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.8/109.3 MB 5.7 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 8.1/109.3 MB 5.7 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 9.4/109.3 MB 5.7 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 10.7/109.3 MB 5.8 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 12.1/109.3 MB 5.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 13.4/109.3 MB 5.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 14.7/109.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 16.0/109.3 MB 6.0 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 17.3/109.3 MB 6.0 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 18.4/109.3 MB 6.0 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 19.7/109.3 MB 5.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 20.7/109.3 MB 5.9 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 22.0/109.3 MB 6.0 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 23.3/109.3 MB 5.9 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 24.4/109.3 MB 5.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 25.7/109.3 MB 5.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 27.0/109.3 MB 5.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 28.0/109.3 MB 5.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 29.4/109.3 MB 5.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 30.4/109.3 MB 5.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 31.7/109.3 MB 5.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 32.8/109.3 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 33.8/109.3 MB 5.8 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 34.9/109.3 MB 5.8 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 36.2/109.3 MB 5.8 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 37.5/109.3 MB 5.8 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 38.8/109.3 MB 5.8 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 40.1/109.3 MB 5.8 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 41.4/109.3 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 42.7/109.3 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 44.0/109.3 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 45.4/109.3 MB 5.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 46.7/109.3 MB 5.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 48.0/109.3 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 49.3/109.3 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 50.6/109.3 MB 5.9 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 51.6/109.3 MB 5.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 53.0/109.3 MB 5.9 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 54.3/109.3 MB 5.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 55.3/109.3 MB 5.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 56.6/109.3 MB 5.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 57.9/109.3 MB 5.9 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 59.0/109.3 MB 5.9 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 60.3/109.3 MB 5.9 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 61.6/109.3 MB 5.9 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 62.9/109.3 MB 5.9 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 64.2/109.3 MB 5.9 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 65.3/109.3 MB 5.9 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 66.6/109.3 MB 5.9 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 67.9/109.3 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 69.2/109.3 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 70.5/109.3 MB 5.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 71.8/109.3 MB 5.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 72.9/109.3 MB 6.0 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 73.9/109.3 MB 5.9 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 75.2/109.3 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 76.8/109.3 MB 6.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 6.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 79.2/109.3 MB 6.0 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 80.5/109.3 MB 6.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 81.8/109.3 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 83.4/109.3 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 84.4/109.3 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 85.7/109.3 MB 6.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 87.3/109.3 MB 6.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 88.3/109.3 MB 6.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 89.7/109.3 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 91.2/109.3 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 92.3/109.3 MB 6.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 93.6/109.3 MB 6.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 94.9/109.3 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 96.2/109.3 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 97.5/109.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 98.8/109.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 100.1/109.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 101.4/109.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 102.5/109.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.8/109.3 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 105.1/109.3 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 106.4/109.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.7/109.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.3/109.3 MB 6.0 MB/s  0:00:18\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.3 MB/s  0:00:00\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, jinja2, fsspec, filelock, torch\n",
      "\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ---------------------------------------- 0/7 [mpmath]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [sympy]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------- ---------------------------- 2/7 [networkx]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ----------------- ---------------------- 3/7 [jinja2]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [fsspec]\n",
      "   ---------------------------- ----------- 5/7 [filelock]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------- ----- 6/7 [torch]\n",
      "   ---------------------------------------- 7/7 [torch]\n",
      "\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install tensorflow\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7854864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff5ae47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text_info</th>\n",
       "      <th>text_info_conf</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917791044158185473</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>RT @Gizmodo: Wildfires raging through Northern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917791130590183424</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>PHOTOS: Deadly wildfires rage in California ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917792092100988929</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>RT @TIME: California's raging wildfires as you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id    text_info  text_info_conf  \\\n",
       "0  917791044158185473  informative          1.0000   \n",
       "1  917791130590183424  informative          1.0000   \n",
       "2  917791291823591425  informative          0.6813   \n",
       "3  917791291823591425  informative          0.6813   \n",
       "4  917792092100988929  informative          0.6727   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  RT @Gizmodo: Wildfires raging through Northern...  \n",
       "1  PHOTOS: Deadly wildfires rage in California ht...  \n",
       "2  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...  \n",
       "3  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...  \n",
       "4  RT @TIME: California's raging wildfires as you...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.read_csv('../data/crisis_texts_dataset.csv')\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aae30523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"he's\", 'they', \"mightn't\", 'shan', 'the', 'ourselves', 'me', \"don't\", 'should', 'ain', 'being', \"she'll\", \"they're\", 'yourselves', 'but', 'ours', 'which', \"it'd\", 'shouldn', \"they've\", \"she'd\", \"i've\", 'who', 'those', 'be', 'a', \"we'll\", 'can', 'am', 'itself', \"they'd\", 'some', 'does', 'mustn', 'd', 'o', 'rt', \"couldn't\", 'once', 'not', 'don', 'has', 'hadn', 'here', 'our', 'before', 'any', 'above', 'an', 'he', 'on', 'other', 'wasn', 'so', 'few', 'during', 'wouldn', 'doing', \"weren't\", 'theirs', 'then', 'myself', \"you'd\", 'and', 'have', \"hadn't\", \"you're\", 'was', 'herself', 'each', 'into', 'them', \"we're\", 'yourself', 'had', 'over', 'very', \"should've\", 'until', 'needn', 'most', 'yours', \"he'll\", 'her', 'him', 'why', 'did', 'll', 'just', 'own', 'will', 'are', 'these', 'to', 'while', \"you've\", \"mustn't\", \"that'll\", 'as', 'if', 're', 'of', 'off', 'only', \"hasn't\", 'that', 'hers', 'himself', \"doesn't\", 'further', \"you'll\", \"they'll\", \"won't\", 'is', \"we've\", 'now', 'down', 't', 'both', 'you', 'nor', 'too', 'their', 'when', 'do', 'from', 'than', 'what', 'been', 'between', 'again', 'in', 'no', 'out', 'aren', \"i'm\", \"needn't\", 'at', 'haven', 'by', 'all', 'his', 'or', 'she', 'about', 'there', 'it', 'm', 'your', 'isn', \"haven't\", 'more', 'RT', 'below', \"he'd\", \"shan't\", 'after', 'weren', \"isn't\", \"i'd\", 'i', 'up', \"wasn't\", 'hasn', 'same', 'couldn', 'this', \"wouldn't\", 've', \"i'll\", 'such', 'its', 'were', 'through', 'under', \"she's\", 'whom', 'won', 'because', \"didn't\", 'for', 'how', 'mightn', 'we', \"we'd\", 'y', \"shouldn't\", 'where', \"it's\", 'against', 'didn', 'ma', 'with', 's', 'themselves', 'my', \"aren't\", 'doesn', \"it'll\", 'having'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\isaja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Para el manejo de stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['rt', 'RT'])\n",
    "print(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28224fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Eliminar caracteres no ASCII\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    # Eliminar números\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Reemplazar signos de puntuación con espacios\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Convertir a minúsculas y eliminar stopwords\n",
    "    text = ' '.join([word.lower() for word in text.split() if word.lower() not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "165f6d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alooooooo happy'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"RT alooooooo #happy http://example.com 123!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2314c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text_info</th>\n",
       "      <th>text_info_conf</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917791044158185473</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>RT @Gizmodo: Wildfires raging through Northern...</td>\n",
       "      <td>gizmodo wildfires raging northern california t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917791130590183424</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>PHOTOS: Deadly wildfires rage in California ht...</td>\n",
       "      <td>photos deadly wildfires rage california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "      <td>cal_oes pls share capturing wildfire response ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "      <td>cal_oes pls share capturing wildfire response ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917792092100988929</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>RT @TIME: California's raging wildfires as you...</td>\n",
       "      <td>time california raging wildfires never seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>917830152159092736</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>RT @CityLab: \"Diablo winds\" are sparking massi...</td>\n",
       "      <td>citylab diablo winds sparking massive wildfire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>917830920907890688</td>\n",
       "      <td>not_informative</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>RT @FFBehavior: California Working. All of it....</td>\n",
       "      <td>ffbehavior california working ap photo rich pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>917831645218136065</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>As Wildfires Spread Through California, Find O...</td>\n",
       "      <td>wildfires spread california find help victims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>917831909111222272</td>\n",
       "      <td>not_informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>An Inferno Like You've Never Seen: Deadly Wild...</td>\n",
       "      <td>inferno like never seen deadly wildfires ravag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>917831945802919938</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>An aerial photo of the devastation left behind...</td>\n",
       "      <td>aerial photo devastation left behind north bay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id        text_info  text_info_conf  \\\n",
       "0   917791044158185473      informative          1.0000   \n",
       "1   917791130590183424      informative          1.0000   \n",
       "2   917791291823591425      informative          0.6813   \n",
       "3   917791291823591425      informative          0.6813   \n",
       "4   917792092100988929      informative          0.6727   \n",
       "..                 ...              ...             ...   \n",
       "95  917830152159092736      informative          1.0000   \n",
       "96  917830920907890688  not_informative          0.6833   \n",
       "97  917831645218136065      informative          0.6466   \n",
       "98  917831909111222272  not_informative          1.0000   \n",
       "99  917831945802919938      informative          0.6563   \n",
       "\n",
       "                                           tweet_text  \\\n",
       "0   RT @Gizmodo: Wildfires raging through Northern...   \n",
       "1   PHOTOS: Deadly wildfires rage in California ht...   \n",
       "2   RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
       "3   RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
       "4   RT @TIME: California's raging wildfires as you...   \n",
       "..                                                ...   \n",
       "95  RT @CityLab: \"Diablo winds\" are sparking massi...   \n",
       "96  RT @FFBehavior: California Working. All of it....   \n",
       "97  As Wildfires Spread Through California, Find O...   \n",
       "98  An Inferno Like You've Never Seen: Deadly Wild...   \n",
       "99  An aerial photo of the devastation left behind...   \n",
       "\n",
       "                                           clean_text  \n",
       "0   gizmodo wildfires raging northern california t...  \n",
       "1             photos deadly wildfires rage california  \n",
       "2   cal_oes pls share capturing wildfire response ...  \n",
       "3   cal_oes pls share capturing wildfire response ...  \n",
       "4         time california raging wildfires never seen  \n",
       "..                                                ...  \n",
       "95  citylab diablo winds sparking massive wildfire...  \n",
       "96  ffbehavior california working ap photo rich pe...  \n",
       "97      wildfires spread california find help victims  \n",
       "98  inferno like never seen deadly wildfires ravag...  \n",
       "99  aerial photo devastation left behind north bay...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['clean_text'] = df_text['tweet_text'].apply(clean_text)\n",
    "df_text.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c17024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ferocious wildfires turn northern california neighborhoods ashes',\n",
       " 'venezuela delivers tons aid earthquake ravaged mexico people telesur english',\n",
       " 'hurricane maria update neighborhood',\n",
       " 'home medicine lka floodsl',\n",
       " 'california wildfires deliberately set',\n",
       " 'hurricane maria competes irma title vicious storm',\n",
       " 'right sample photos tennessee civil air patrol taken puerto rico wate news',\n",
       " 'wjxt mexico earthquake latest',\n",
       " 'hurricane maria lashes nc outer banks',\n",
       " 'wx_maps tornado severe thunderstorm flash flood warnings month august']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra aleatoria de textos limpios\n",
    "import random\n",
    "random.sample(list(df_text['clean_text']), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55c0d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('informative', 'gizmodo wildfires raging northern california terrifying'),\n",
       " ('informative', 'photos deadly wildfires rage california'),\n",
       " ('informative',\n",
       "  'cal_oes pls share capturing wildfire response recovery info'),\n",
       " ('informative',\n",
       "  'cal_oes pls share capturing wildfire response recovery info'),\n",
       " ('informative', 'time california raging wildfires never seen'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = tuple((row['informative'], row['clean_text']) for _, row in df_text.iterrows())\n",
    "dataset = tuple(\n",
    "    (row['text_info'], row['clean_text'])\n",
    "    for _, row in df_text.iterrows() \n",
    ")\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0804b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del set de entrenamiento: 13561\n",
      "Tamaño del set de validación: 2712\n",
      "Tamaño del set de prueba: 1809\n",
      "\n",
      "Ejemplos del set de entrenamiento:\n",
      "('not_informative', 'newsarama peanuts schulz museum closed due approaching california wildfires')\n",
      "('informative', 'heartwarming fundraiser hurricane maria cambridge police station')\n",
      "('not_informative', 'jacksonw mother nature putting show sebago lake wcsh noaa funnelcloud tornado')\n",
      "\n",
      "Ejemplos del set de validación:\n",
      "('informative', 'california wildfires cost state bn insurance commissioner')\n",
      "('informative', 'realdonaldtrump people puerto rico electricity read tweet')\n",
      "('informative', 'kprc texans plan honor harvey heroes sunday liberty whiteout game')\n",
      "\n",
      "Ejemplos del set de prueba:\n",
      "('informative', 'irma jose maria remind us september hurricane time arstechnica sciguyspace')\n",
      "('informative', 'tornado fall close match north greenville')\n",
      "('not_informative', 'jonsered mora truth power song playlist')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import random_split\n",
    "from random import sample\n",
    "\n",
    "# Proporciones\n",
    "train_ratio = 0.75\n",
    "dev_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Longitudes\n",
    "train_len = int(len(dataset) * train_ratio)\n",
    "dev_len = int(len(dataset) * dev_ratio)\n",
    "test_len = len(dataset) - train_len - dev_len  # para evitar problemas de redondeo\n",
    "\n",
    "# Dividimos el dataset\n",
    "train_split, dev_split, test_split = random_split(dataset, [train_len, dev_len, test_len])\n",
    "\n",
    "print(f\"Tamaño del set de entrenamiento: {len(train_split)}\")\n",
    "print(f\"Tamaño del set de validación: {len(dev_split)}\")\n",
    "print(f\"Tamaño del set de prueba: {len(test_split)}\")\n",
    "\n",
    "# Mostramos algunos ejemplos\n",
    "print(\"\\nEjemplos del set de entrenamiento:\")\n",
    "for example in sample(list(train_split), 3):\n",
    "    print(example)\n",
    "print(\"\\nEjemplos del set de validación:\")\n",
    "for example in sample(list(dev_split), 3):\n",
    "    print(example)\n",
    "print(\"\\nEjemplos del set de prueba:\")\n",
    "for example in sample(list(test_split), 3):\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1073207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\isaja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenización\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc457351",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = namedtuple('tweet', ['text', 'label'])\n",
    "\n",
    "tokenized_train_set = [document(text=word_tokenize(d[1]), label=d[0]) for d in train_split]\n",
    "train_set = pd.DataFrame(tokenized_train_set)\n",
    "\n",
    "tokenized_dev_set = [document(text=word_tokenize(d[1]), label=d[0]) for d in dev_split]\n",
    "dev_set = pd.DataFrame(tokenized_dev_set)\n",
    "\n",
    "tokenized_test_set = [document(text=word_tokenize(d[1]), label=d[0]) for d in test_split]\n",
    "test_set = pd.DataFrame(tokenized_test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6fc17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cffd6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de nuestro modelo\n",
    "\n",
    "class CrisisCNN:\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim=300,\n",
    "                 max_sequence_length=100,\n",
    "                 num_classes=2):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        # Input layer\n",
    "        input_layer = layers.Input(shape=(self.max_sequence_length,))\n",
    "        \n",
    "        # Embedding layer\n",
    "        embedding = layers.Embedding(\n",
    "            input_dim=self.vocab_size,\n",
    "            output_dim=self.embedding_dim,\n",
    "            input_length=self.max_sequence_length,\n",
    "            trainable=False\n",
    "        )(input_layer)\n",
    "        \n",
    "        # Batch normalization after embedding\n",
    "        x = layers.BatchNormalization()(embedding)\n",
    "        \n",
    "        # Parallel convolutional layers\n",
    "        conv_blocks = []\n",
    "        \n",
    "        # 100 filters, window size 2\n",
    "        conv1 = layers.Conv1D(\n",
    "            filters=100,\n",
    "            kernel_size=2,\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        pool1 = layers.GlobalMaxPooling1D()(conv1)\n",
    "        conv_blocks.append(pool1)\n",
    "        \n",
    "        # 150 filters, window size 3\n",
    "        conv2 = layers.Conv1D(\n",
    "            filters=150,\n",
    "            kernel_size=3,\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        pool2 = layers.GlobalMaxPooling1D()(conv2)\n",
    "        conv_blocks.append(pool2)\n",
    "        \n",
    "        # 200 filters, window size 4\n",
    "        conv3 = layers.Conv1D(\n",
    "            filters=200,\n",
    "            kernel_size=4,\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        pool3 = layers.GlobalMaxPooling1D()(conv3)\n",
    "        conv_blocks.append(pool3)\n",
    "        \n",
    "        # Concatenate all convolutional blocks\n",
    "        concatenated = layers.Concatenate()(conv_blocks)\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = layers.Dropout(0.2)(concatenated)\n",
    "        \n",
    "        # 5 Fully connected hidden layers\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.02)(x)\n",
    "        \n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.02)(x)\n",
    "        \n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.02)(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.02)(x)\n",
    "        \n",
    "        x = layers.Dense(32, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.02)(x)\n",
    "        \n",
    "        # Output layer\n",
    "        output_layer = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        \n",
    "        model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self):\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(learning_rate=0.01),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=0.0001,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74e7838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\isaja\\documents\\dcc\\e\\crisis\\env\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f74f8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab502a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_for_cnn(train_set, dev_set, test_set, max_sequence_length=100):\n",
    "    \"\"\"\n",
    "    Prepara secuencias para la CNN desde DataFrames con textos tokenizados\n",
    "    \"\"\"\n",
    "    # Convertir listas de tokens a texto para el tokenizer\n",
    "    def tokens_to_text(token_list):\n",
    "        return ' '.join(token_list)\n",
    "    \n",
    "    # Preparar textos\n",
    "    train_texts = [tokens_to_text(tokens) for tokens in train_set['text']]\n",
    "    dev_texts = [tokens_to_text(tokens) for tokens in dev_set['text']]\n",
    "    test_texts = [tokens_to_text(tokens) for tokens in test_set['text']]\n",
    "    \n",
    "    # Preparar labels (convertir a numéricos si es necesario)\n",
    "    def prepare_labels(labels):\n",
    "        # Si los labels son strings, convertirlos a numéricos\n",
    "        if isinstance(labels.iloc[0], str):\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            return le.fit_transform(labels)\n",
    "        return labels.values\n",
    "    \n",
    "    y_train = prepare_labels(train_set['label'])\n",
    "    y_dev = prepare_labels(dev_set['label'])\n",
    "    y_test = prepare_labels(test_set['label'])\n",
    "    \n",
    "    # Crear y ajustar tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    \n",
    "    # Convertir a secuencias\n",
    "    X_train = tokenizer.texts_to_sequences(train_texts)\n",
    "    X_dev = tokenizer.texts_to_sequences(dev_texts)\n",
    "    X_test = tokenizer.texts_to_sequences(test_texts)\n",
    "    \n",
    "    # Aplicar padding\n",
    "    X_train = pad_sequences(X_train, maxlen=max_sequence_length, padding='post')\n",
    "    X_dev = pad_sequences(X_dev, maxlen=max_sequence_length, padding='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=max_sequence_length, padding='post')\n",
    "    \n",
    "    return X_train, X_dev, X_test, y_train, y_dev, y_test, tokenizer\n",
    "\n",
    "def load_pretrained_embeddings(embedding_path, tokenizer, embedding_dim=300):\n",
    "    \"\"\"\n",
    "    Carga embeddings pre-entrenados word2vec\n",
    "    \"\"\"\n",
    "    embeddings_index = {}\n",
    "    \n",
    "    try:\n",
    "        with open(embedding_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                if len(values) < embedding_dim + 1:\n",
    "                    continue\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:embedding_dim+1], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Archivo de embeddings no encontrado: {embedding_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Crear matriz de embeddings\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "    words_found = 0\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            words_found += 1\n",
    "    \n",
    "    print(f\"Palabras encontradas en embeddings: {words_found}/{len(tokenizer.word_index)}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a3149bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1fd04af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento CNN...\n",
      "Preparando datos...\n",
      "Tamaño del vocabulario: 19025\n",
      "Forma de X_train: (13561, 100)\n",
      "Forma de y_train: (13561,)\n",
      "Construyendo modelo CNN...\n",
      "Cargando embeddings pre-entrenados...\n",
      "Archivo de embeddings no encontrado: path/to/word2vec/embeddings.txt\n",
      "Usando embeddings aleatorios\n",
      "Compilando modelo...\n",
      "Iniciando entrenamiento...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m243/424\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.6796 - loss: 0.6511"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_model, history, tokenizer, test_accuracy\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIniciando experimento CNN...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m model, history, tokenizer, test_accuracy = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdev_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpath/to/word2vec/embeddings.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Para usar después (tal vez)\u001b[39;49;00m\n\u001b[32m     56\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(train_set, dev_set, test_set, embedding_path)\u001b[39m\n\u001b[32m     38\u001b[39m cnn_model.compile_model()\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIniciando entrenamiento...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m history = \u001b[43mcnn_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluando en test set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mCrisisCNN.train\u001b[39m\u001b[34m(self, X_train, y_train, X_val, y_val, epochs, batch_size)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train, y_train, X_val, y_val, epochs=\u001b[32m50\u001b[39m, batch_size=\u001b[32m32\u001b[39m):\n\u001b[32m    104\u001b[39m     callbacks = [\n\u001b[32m    105\u001b[39m         EarlyStopping(\n\u001b[32m    106\u001b[39m             monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m         )\n\u001b[32m    118\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaja\\Documents\\dcc\\e\\crisis\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_experiment(train_set, dev_set, test_set, embedding_path=None):\n",
    "    \"\"\"\n",
    "    Ejecuta el experimento completo de CNN\n",
    "    \"\"\"\n",
    "    print(\"Preparando datos...\")\n",
    "    X_train, X_dev, X_test, y_train, y_dev, y_test, tokenizer = prepare_sequences_for_cnn(\n",
    "        train_set, dev_set, test_set\n",
    "    )\n",
    "    \n",
    "    print(f\"Tamaño del vocabulario: {len(tokenizer.word_index)}\")\n",
    "    print(f\"Forma de X_train: {X_train.shape}\")\n",
    "    print(f\"Forma de y_train: {y_train.shape}\")\n",
    "    \n",
    "    # Crear modelo\n",
    "    print(\"Construyendo modelo CNN...\")\n",
    "    cnn_model = CrisisCNN(\n",
    "        vocab_size=len(tokenizer.word_index) + 1,\n",
    "        embedding_dim=300,\n",
    "        max_sequence_length=100,\n",
    "        num_classes=len(np.unique(y_train))\n",
    "    )\n",
    "    \n",
    "    # Cargar embeddings pre-entrenados si están disponibles\n",
    "    if embedding_path:\n",
    "        print(\"Cargando embeddings pre-entrenados...\")\n",
    "        embedding_matrix = load_pretrained_embeddings(embedding_path, tokenizer)\n",
    "        if embedding_matrix is not None:\n",
    "            cnn_model.model.layers[1].set_weights([embedding_matrix])\n",
    "            print(\"Embeddings pre-entrenados cargados exitosamente\")\n",
    "        else:\n",
    "            print(\"Usando embeddings aleatorios\")\n",
    "    else:\n",
    "        print(\"Usando embeddings aleatorios (entrenables)\")\n",
    "        # Si no hay embeddings pre-entrenados, hacerlos entrenables\n",
    "        cnn_model.model.layers[1].trainable = True\n",
    "    \n",
    "    print(\"Compilando modelo...\")\n",
    "    cnn_model.compile_model()\n",
    "    \n",
    "    print(\"Iniciando entrenamiento...\")\n",
    "    history = cnn_model.train(X_train, y_train, X_dev, y_dev)\n",
    "    \n",
    "    print(\"Evaluando en test set...\")\n",
    "    test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return cnn_model, history, tokenizer, test_accuracy\n",
    "\n",
    "print(\"Iniciando experimento CNN...\")\n",
    "model, history, tokenizer, test_accuracy = run_experiment(\n",
    "    train_set, \n",
    "    dev_set, \n",
    "    test_set,\n",
    "    embedding_path='path/to/word2vec/embeddings.txt' # Para usar después (tal vez)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
